\documentclass[11pt]{article}

\usepackage{graphicx}
\usepackage{wrapfig}
\usepackage{url}
\usepackage{wrapfig}
\usepackage{color}
\usepackage{marvosym}
\usepackage{enumerate}
\usepackage{subfigure}
\usepackage{tikz}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{hyperref} 
\usepackage{listings}

\oddsidemargin 0mm
\evensidemargin 5mm
\topmargin -20mm
\textheight 240mm
\textwidth 160mm

\def\ci{\perp\!\!\!\perp}

\pagestyle{myheadings} 
\markboth{Homework 1}{Fall 2018 CS 477/677 Causal Inference: Homework 1} 

\title{CS 477/677 Causal Inference: Homework 1\\Probability and Statistics\\
\Large{Due: Friday September 21, 2018, 11:59pm}\\
50 Points Total}
\author{Ilya Shpitser\\ \texttt{ilyas@cs.jhu.edu}}
\date{}

\begin{document}
\large
\maketitle
\thispagestyle{headings}

\vspace{-.5in}

\definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{gray}{rgb}{0.5,0.5,0.5}
\definecolor{mauve}{rgb}{0.58,0,0.82}

\lstset{frame=tb,
  language=R,
  aboveskip=3mm,
  belowskip=3mm,
  showstringspaces=false,
 columns=flexible,
  basicstyle={\small\ttfamily},
  numbers=none,
  numberstyle=\tiny\color{gray},
  keywordstyle=\color{blue},
  commentstyle=\color{dkgreen},
  stringstyle=\color{mauve},
  breaklines=true,
  breakatwhitespace=true,
  tabsize=3
}

\lstset{language=R}

\section{Introduction}

Homeworks in this class will consist of a programming part and a conceptual part.

\subsection{Programming Assignments and the Background on the R Language}

The programming part of the homework is meant to familiarize you with tools needed to perform causal inferences from data, and give you a chance to practice doing such analyses.  This part will involve writing and running code, and perhaps answering some questions about the results.
You will implement all assignments using the R programming language.  Submissions in other languages will not be accepted.  R is a very powerful high level programming language for data analysis and statistical computing.  While no programming language is perfect, R's expressiveness and built in functions for common statistical operations will make writing data analysis programs simple compared to more "heavy duty" general purpose languages such as Java.  R's semantics resemble the LISP programming language in many ways, while R's syntax resembles standard syntax used by the Algol family of languages (such as C, C$++$, Java, and python).  If you are familiar with one of these languages, R will not be difficult for you to pick up and use.  R can be downloaded for free at \href{https://www.r-project.org/}{https://www.r-project.org/}.

The R language has many predefined functions and a very large number of contributed packages for all sorts of things.  To help you navigate, we will generally give suggestions for which functions or packages might be relevant.  R is an interpreted programming language.  You can evaluate code directly using a "read eval print loop" interpreter, load R scripts into an interpreter and run it there, or run R scripts from the command line using the command \texttt{Rscript} that comes with R.  The most important R function for a beginner is \texttt{help(.)}.  You can use it get a detailed description of any built in function in R, and generally on functions that are implemented in packages you download (provided those packages are well-documented!)

\subsection{Conceptual Assignments and the Background on Latex}

The conceptual part of the homework is meant to help you think through the philosophical and mathematical issues involved in causal inference.
This part may involve manual calculation, mathematical and logical arguments, perhaps even essay questions.  Your answers to the conceptual
part of the homework must be submitted as a pdf file generated by latex.  Latex is a very powerful typesetting system particularly useful for writing scientific and mathematical documents.  While latex involves a bit of a learning curve compared to ``what you see is what you get'' editors such as Microsoft Word, the time investment is generally worth it.  If you want to write scientific publications, latex is always a safe choice, as many journals and peer reviewed conferences have standardized on it.  Latex can be viewed as a programming language that is compiled into a pdf file.
A latex source file contains a combination of plain text and directives that instruct the compiler how to typeset the document.  We recommend you use the command \texttt{pdflatex} to convert latex source code into pdf.  This command is generally available on most common operating systems in use today.  We will provide the latex source code for every homework assignment that we recommend you use as a standard point for the conceptual part of the assignment.

\section{Programming (20 Points)}

In this part of the assignment, you will familiarize yourself with the R language, and write functions for creating data frames (R data structures used to represent data sets), performing non-parametric bootstrap, constructing confidence intervals for any statistic of interest, and fitting parameters in a logistic regression model by solving estimating equations using the Newton-Raphson method.  Unless otherwise stated, pleased implement all code yourself (even if an existing implementation already exists as a package, or even a part of standard R!)

\subsection{Logistic Regression (10 Points)}

You will implement fitting of a logistic regression model via solving estimating equations using a data set
included with the homework.  The following description of the dataset appears in
\cite{vinod10advances}, Chapter 8:
\begin{quotation}
This dataset is from the Job Search Intervention Study (JOBS II) \cite{vinokur97mastery}.
In the JOBS II field experiment, 1,801 unemployed workers received a pre-screening
questionnaire and were then randomly assigned to treatment and control
groups.  Those in the treatment group participated in job-skills workshops.
Those in the control condition received a booklet describing job-search tips. In
follow-up interviews, two key outcome variables were measured: a continuous
measure of depressive symptoms based on the Hopkins Symptom Checklist
(\texttt{depress2}), and a binary variable representing whether the respondent had
become employed (\texttt{work1}). In the JOBS II data, a continuous measure of
job-search self-efficacy represents a key mediating variable (\texttt{job\_seek}). In
addition to the outcome and mediators, the JOBS II data also include the
following list of baseline covariates that were measured prior to the administration
of the treatment: pretreatment level of depression (\texttt{depress1}), education
(\texttt{educ}), income, race (nonwhite), marital status (\texttt{marital}), age, sex,
previous occupation (\texttt{occp}), and the level of economic hardship (\texttt{econ\_hard}).
\end{quotation}

In this assignment, we will use a subset of the original dataset for which complete data on all
features and outcome is available.  We will discuss how to handle missing data later in the course.
Your regression model will regress an intercept (represented by a column of $1$s) and variables
\texttt{treat, econ\_hard,} \texttt{depress1, sex, age, occp, marital, nonwhite, educ, income,} and
\texttt{job\_seek} (the first 11 columns of the dataset) with the binarized outcome variable \texttt{outcome} (which will
be added as the 17th column of the dataset).  Your logistic regression function will take extra arguments,
the third is a closure (more on closures below) representing a function $A({\bf X})$, and the fourth is $\texttt{tol}$,
which governs how close successive guesses of the parameters have to be before the Newton-Raphson loop exits.
Your logistic regression function will solve, via Newton-Raphson, the estimating equations
\[
\sum_{i=1}^n A({\bf x}_{i(1:k)}) \{ y_i - \mu({\bf x}_{i(1:k)}; {\bf w})\} = 0.
\]
Your Newton-Raphson implemention ought to be able to handle any reasonable function $A({\bf X})$.  See question 2 in section 2.2.2 below.

Please do not use any built in R functions for fitting in this assignment,
and implement fitting directly using matrix manipulation.  You may find the matrix inversion function
\texttt{solve(.)} and the matrix multiplication operator \texttt{\%*\%} helpful.

\begin{lstlisting}
# Input:
#           X,y: a training dataset given as a set of feature rows, represented
#           by a n by k matrix X, and a set of corresponding
#           output predictions, represented by a n by 1 matrix y.
#           A: a function of the features x, used in estimating equations.
#           tol: tolerance used to exit the Newton-Raphson loop.
# Output:
#           A row vector of weights for a logistic regression model (with no intercept)
#           maximizing the likelihood of observing the data.
logisreg = function(X, y, A, tol = 0.01){

}
\end{lstlisting}

\subsection{The Bootstrap}

\subsubsection{Implementation (6 Points)}

You will implement the following four functions.

\begin{lstlisting}
# Input:
#           mat: a matrix with n rows and k columns (rows are samples, columns are
#           variables).
# Output:   a data frame with column (variable) names "x1" to "xk", and data from the
#           matrix.
df_make = function(mat){

}
\end{lstlisting}

This function merely wraps a data frame around a matrix representing a data set, and gives standard names to columns (representing features or variables in our data).  You might find functions \texttt{matrix(.)}, \texttt{as.data.frame(.)}, \texttt{dim(.)}, \texttt{paste(.)} and \texttt{colnames(.)} helpful.

\begin{lstlisting}
# Input:
#           df: a data frame with n rows to be resampled.
# Output:   a data frame with n rows obtained from the input dataframe
#           by sampling rows with replacement.
df_resample = function(df){

}
\end{lstlisting}

This function constructs an appropriately resampled dataset used in nonparametric bootstrap.  You might find the function
\texttt{sample(.)}, and reading up on R's \texttt{1:k} syntactic sugar notation for generating vectors helpful.

\begin{lstlisting}
# Input:
#           df: a data frame to be resampled
#           k: number of resampled datasets to generate.
#           f: a function of df giving the bootstrap statistic
#           (e.g. function(df) { mean(df$x1) })
#           q: a real number 0 < q < 0.5 giving the lower quantile of the desired
#           confidence interval.
# Output:   a four element vector giving the statistic of interest (first element),
#           and lower and upper confidence intervals corresponding to
#           q and 1-q quantiles (second and third elements) of the empirical
#           bootstrap distribution, and the size of the confidence interval.
bootstrap_ci = function(df, k, f, q){

}
\end{lstlisting}

This function uses non-parametric bootstrap to construct confidence intervals around a parameter of interest.  We will use a particular rule which estimates this parameter using a data set.  For example, if we were interested in the mean of the variable $X_1$, and we had data frame with a set of values for $X_1$, then we could use the maximum likelihood procedure for the mean.  We will implement these rules by a \emph{reified function}, sometimes known as a \emph{closure} passed as the third argument.  A closure that calculates the mean of $X_1$ from a data frame \texttt{df} could be constructed as follows:
\begin{center}
\texttt{ f = function(df) \{ mean(df\$x1) \}}
\end{center}
This creates a variable \texttt{f} in R which is a function of one argument, that expects a data frame, and which calculates and returns the mean of the \texttt{x1} column of this data frame.  This variable can be treated as an ordinary variable and passed around to other functions, and it can be evaluated at any point by calling the variable with an argument: \texttt{f(df)}.

The function you will implement will first evaluate \texttt{f} on the original data set to obtain the statistic, generate \texttt{k} resampled data sets using the function \texttt{df\_resample} above, store the values of the statistic of interest for each of these resampled datasets, and obtain the appropriate  confidence intervals using the \texttt{quantile(.)} function applied to the difference of the original statistic, and the vector of statistics obtained from the resampled datasets, corresponding to the empirical bootstrap distribution.  Remember, reported confidence intervals are centered around the statistic of interest.  For example, if the statistic is an estimated mean of $3.2$, the $0.05$ quantile is $-0.72$, and the $0.95$ quantile is $0.68$, we report the vector $3.2, 2.48, 3.88, 1.4$.

You will use the following main function, please do not change it.
\begin{lstlisting}
# Input:
#           none
# Output:
#           none
main = function(){

    # set the seed for the pseudo-random number generator.
    set.seed(0)
    # set the tolerance for Newton-Raphson.
    tol <- 0.01
    
    # load the dataset
    dat <- read.table("Jobs-NoMiss-Cont.tab", header = TRUE)

    # add a binarized version of depress2 called `outcome.'
    dat$outcome = 1 * (dat$depress2 >= 2)
    
    m <- as.matrix(dat)
    
    y <- m[,17, drop=FALSE]
    X <- m[,1:11]
    X <- cbind(rep(1, dim(X)[1]), X)

    A1 = function(x){
        x
    }

    w1 <- logisreg(X, y, A1, tol)

    print(w1)

    A2 = function(x){
        x^2
    }

    w2 <- logisreg(X, y, A2, tol)

    print(w2)
    
    k <- 3

    mu <- c(1, 2, 3)

    Sigma <- matrix(c(1, 1, 1, 1, 3, 1, 1, 1, 5), k, k)

    n <- 1000

    dat <- mvrnorm(n = n, mu, Sigma)

    df <- df_make(dat)

    mean_1 <- function(df) { mean(df$x1) }
    mean_2 <- function(df) { mean(df$x2) }

    k <- 1000

    print(bootstrap_ci(df, k, mean_1, 0.025))
    print(bootstrap_ci(df, k, mean_2, 0.025))
}
\end{lstlisting}

\begin{lstlisting}
main()
\end{lstlisting}
Place this call at the end of your file such that running it as a script will evaluate the entry point function.

\subsubsection{Questions (4 Points)}

\paragraph{1}
The bootstrap calls in \texttt{main()} give the confidence intervals for $\mathbb{E}[X_1]$ and $\mathbb{E}[X_2]$ where $(X_1,X_2,X_3)$ are drawn from the following
multivariate normal distribution:
\[
{\cal N}\left( (1,2,3), \left(\begin{array}{ccc} 1 & 1 & 1 \\ 1 & 3 & 1 \\ 1 & 1 & 5 \end{array} \right) \right).
\]
Out of the confidence intervals reported in \texttt{main()}, which confidence interval is wider, for the mean of $X_1$ or the mean of $X_2$?
Why do you think that is?

\paragraph{2}
Consider the vector function (of size $k \times 1$): $\sum_{i=1}^n A({\bf x}_{i(1:k)}) \{ y_i - \mu({\bf x}_{i(1:k)}; {\bf w})\}$.
Compute the derivative of this function with respect to ${\bf w}$.  Note that you should end up with a $k \times k$ matrix of derivatives.

\section{Analytical (30 Points)}

\paragraph{1 (4 points)}
Consider the following definitions of ``actual causation'' (one event causing another):
\begin{itemize}
\item[1] $A$ causes $B$ if the Pearson correlation coefficient $\rho_{AB}$ is not equal to $0$.  The Pearson correlation coefficient is defined as
\[
\rho_{AB} = \frac{\text{cov}(A,B)}{\sigma_A \sigma_B},
\]
where $\sigma_A$ is the standard deviation of $A$.

\item[2] $A$ causes $B$ if $A \not\ci B$ (meaning $A$ is not marginally independent of $B$).
\item[3] $A$ causes $B_t$ if $A \not\ci B_t \mid B_{t-1}$ and $A$ occurs prior to $B_t$ in time.  Here $B_t$ and $B_{t-1}$ are versions of a reoccurring variable $B$ measured at time $t$ and $t-1$.
\item[4] $A$ causes $B$ if $A$ occurs prior to $B$ in time, and if $A$ had not happened, $B$ would not have happened.
\end{itemize}
For each definition, explain if it is reasonable.  If not reasonable, write down a counterexample: a situation which obeys the definition but which intuitively does not correspond to what we mean when we say ``$A$ causes $B$.''

\paragraph{2 (4 points)}
Show that the logistic regression model lies in the restricted moments model:
$Y = \mu({\bf X}; \beta) + \epsilon$, where $\mathbb{E}[\epsilon \mid {\bf X}] = 0$.

\paragraph{3 (3 points)}
Give three examples of \emph{cargo cult behavior} in human beings: that is behavior based on an incorrect attribution of causation to an event.  More on cargo cults can be found here:
\begin{center}
\href{https://en.wikipedia.org/wiki/Cargo\_cult}{https://en.wikipedia.org/wiki/Cargo\_cult}
\end{center}
Please don't use this example, obviously.

\paragraph{4 (4 points)}

Given an example of an inaccurate but precise estimator that gets lower MSE than an accurate but imprecise estimator.

\paragraph{5 (5 points)}

Show that the property $({\bf A} \ci_{\cal G} {\bf B} \mid {\bf C})$, meaning ``in an undirected graph ${\cal G}$, all undirected paths from a vertex $A$ in a set of vertices ${\bf A}$ to a vertex $B$ in a set of vertices ${\bf B}$ is intersected by a subset of vertices in ${\bf C}$,'' satisfies the semi-graphoid axioms.

\paragraph{6 (6 points)}

Show that if $p(C,A,Y)$ is a distribution, then for any value $a$ of $A$,
\[
q_a(Y, C) = p(Y \mid A = a, C) p(C)
\]
is also a distribution.  That is, show $q_a(y,c) \geq 0$ for any $y,c$, and $\sum_{y,c} q_a(y,c) = 1$.

\paragraph{7 (4 points)}
Simpson's paradox occurs in joint distributions $p(Y,A,C)$ where
%{\small
\begin{align}
(\exists y, a_1, a_2) \text{ s.t. }p(y | a_1) < p(y | a_2), \text{ but } (\forall c) \text{ } p(y | a_1,c) \geq p(y | a_2,c).
\label{eqn:simpson}
\end{align}
%}
Define $q_a(Y,C)$ as in question 1, and let $q_a(Y) = \sum_C q_a(Y,C)$, $q_a(Y \mid C) = q_a(Y,C) / q_a(C)$.
Show that the negation of (\ref{eqn:simpson}) holds for $q_a$.  In other words, show that
\begin{align*}
(\forall y, a_1, a_2) [ (\forall c) \text{ }q_{a_1}(y \mid c) \geq q_{a_2}(y \mid c) ] \Rightarrow [q_{a_1}(y) \geq q_{a_2}(y) ].
\end{align*}

\section{How to Submit}

You can obtain the assignment from the class Piazza page. You will submit the assignment on Gradescope. There will generally be no extensions to the listed deadline.

\section{What to Submit}
A pdf file named homework1.pdf, and an R script named homework1.R.  Please include your name, and email at the top of both files.

\section{Questions?}
You can ask questions about the homework, or any other aspect of the class at the class piazza page, found here:
\begin{center}
\href{http://piazza.com/jhu/fall2018/cs600477677/home}{http://piazza.com/jhu/fall2018/cs600477677/home}
\end{center}

To signup for piazza for the class, follow this link:
\begin{center}
\href{http://piazza.com/jhu/fall2018/cs600477677}{http://piazza.com/jhu/fall2018/cs600477677}
\end{center}

\begin{thebibliography}{1}

\bibitem{vinod10advances}
Hrishikesh~D. Vinod.
\newblock {\em Advances in Social Science Research Using R}.
\newblock Springer-Verlag New York, 2010.

\bibitem{vinokur97mastery}
A.~Vinokur and Y.~Schul.
\newblock Mastery and inoculation against setbacks as active ingredients in the
  jobs intervention for the unemployed.
\newblock {\em Journal of Consulting and Clinical Psychology}, 65(5):867--877,
  1997.

\end{thebibliography}

\end{document}
